{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "24bac6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "import PIL.Image as Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94318a99",
   "metadata": {},
   "source": [
    "**Firstly, you install all the pytorch packages by importing the torch libraries above as shown above.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb09e5b",
   "metadata": {},
   "source": [
    "**Let's create a random image data array. Say it's a 32 by 32 black-and-white pixel image.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "28a8ce0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.6063012 , 0.54967946, 0.00154616, ..., 0.35343838,\n",
       "          0.09142447, 0.44434983],\n",
       "         [0.42552126, 0.68634622, 0.04294206, ..., 0.34019779,\n",
       "          0.32486761, 0.56017614],\n",
       "         [0.78396597, 0.44993023, 0.98760553, ..., 0.00121494,\n",
       "          0.33540856, 0.51243502],\n",
       "         ...,\n",
       "         [0.96956422, 0.11109589, 0.59022536, ..., 0.84303002,\n",
       "          0.7483073 , 0.95650451],\n",
       "         [0.81154883, 0.66999489, 0.94750721, ..., 0.47365276,\n",
       "          0.30178989, 0.47881601],\n",
       "         [0.7215737 , 0.64049223, 0.2452134 , ..., 0.71295936,\n",
       "          0.80275813, 0.66278304]]]])"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = np.random.uniform(0, 1, size=(1, 1, 32, 32))\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "3dc4e2b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 32, 32)"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea816572",
   "metadata": {},
   "source": [
    "**We put it in 1 by 1 by 32 by 32 pixel format because it is 1 batch of 1 channels of 32 by 32 pixel data - for now.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "f67a1127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ff7ec7b400>"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img[0][0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4912ff19",
   "metadata": {},
   "source": [
    "**This is only random data for now. We can't classify this as anything but we will attempt to use this junk as demonstration to learn how Resnet CNN works.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "ebc1ae17",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels = 1, out_channels = 4, kernel_size = 5, stride = 2, padding = 2),\n",
    "        nn.BatchNorm2d(num_features = 4),\n",
    "        nn.ReLU())\n",
    "\n",
    "max_pool = nn.MaxPool2d((2, 2), stride = 2)\n",
    "\n",
    "next_convs = nn.Sequential(\n",
    "            nn.Conv2d(4, 16, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU())\n",
    "\n",
    "fc = nn.Sequential(\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54fa566",
   "metadata": {},
   "source": [
    "**Before inputting your data, always make sure that your input-data is a torch tensor variable. Otherwise, back-propagation won't be possible**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "f7df08bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 32, 32])"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = torch.tensor(img, dtype = torch.float32)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "7878db39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 16, 16])"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = conv1(img)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d05d36",
   "metadata": {},
   "source": [
    "**After running through the convolution layer, the data turned from 1 batch of 1 channel of 32 by 32 pixel data to 1 batch of 4 channels of 16 by 16 pixel data. This is due to the 5 by 5 kernel that passed over pixel data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "0545e0e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 8, 8])"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = max_pool(img)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9030a531",
   "metadata": {},
   "source": [
    "**Max pooling simply takes the maximum data value in a *x* by *y* kernel. For every 2 by 2 block in *img*, we pooled only the maximum value, therefore the image turned into 1 batch by 4 channels of 8 by 8 pixel data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "ce912f1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 4, 4])"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = next_convs(img)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da582c6a",
   "metadata": {},
   "source": [
    "**Although there is only 1 layer of convolutions in this example, the data will pass through multiple layers of convolutions as shown in the example above.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "6058e4db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256])"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = img.view(img.shape[0], -1)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9831cf3e",
   "metadata": {},
   "source": [
    "**After this, flatten the data into your batch amount by 1 line of data so that it may be passed through a fully connected layer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "3173def1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = fc(img)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25da6123",
   "metadata": {},
   "source": [
    "**After passing through the fully-connected layer, you can classify what the image data holds by looking at what it could be of 10 choices.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2dcb3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a197b75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b8b133",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "746ffa9d",
   "metadata": {},
   "source": [
    "**Of course, the above was only a simplified version of a resnet network. A real resnet network looks like what would be shown below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "445eb971",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, identity_downsample=None, stride=1):\n",
    "        super(Block, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.identity_downsample = identity_downsample\n",
    "        \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        if self.identity_downsample is not None:\n",
    "            identity = self.identity_downsample(identity)\n",
    "        x += identity\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "e4171ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet_18(nn.Module):\n",
    "    \n",
    "    def __init__(self, image_channels, num_classes):\n",
    "        \n",
    "        super(ResNet_18, self).__init__()\n",
    "        \n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        #resnet layers\n",
    "        self.layer1 = self.__make_layer(64, 64, stride=1)\n",
    "        self.layer2 = self.__make_layer(64, 128, stride=2)\n",
    "        self.layer3 = self.__make_layer(128, 256, stride=2)\n",
    "        self.layer4 = self.__make_layer(256, 512, stride=2)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "        \n",
    "    def __make_layer(self, in_channels, out_channels, stride):\n",
    "        \n",
    "        identity_downsample = None\n",
    "        if stride != 1:\n",
    "            identity_downsample = self.identity_downsample(in_channels, out_channels)\n",
    "            \n",
    "        return nn.Sequential(\n",
    "            Block(in_channels, out_channels, identity_downsample=identity_downsample, stride=stride), \n",
    "            Block(out_channels, out_channels)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "        return x \n",
    "    \n",
    "    def identity_downsample(self, in_channels, out_channels):\n",
    "        \n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1), \n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
